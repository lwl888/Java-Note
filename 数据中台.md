# 基础概念

数据中台定义：数据中台是一套可持续“让企 业的数据用起来”的机制，是一种战略选择和组织形式，是依据企业特有的业务模式和组织架构，通过有形的产品和实施方法论支撑，构建的 一套持续不断把数据变成资产并服务于业务的机制。

## 核心能力

四个核心能力：数据中台需要具备数据汇聚整合、数据提纯加工、数据服务可视化、数据价值变现4个核心能力，让企业员工、客户、伙伴能够方便地应用数 据。

## 数据中台 vs 业务中台

业务中台更多偏向于业务流程管控，将业务流程中共性的服务抽象出 来，形成通用的服务能力

业务中台是抽象业务流程的共性形成通用业务服务能力，而数据中台则 是抽象数据能力的共性形成通用数据服务能力

## 数据整体 vs 数据仓库

数据仓库的主要场景是支持管理决策和业务分析，而数据中台则是将数据服务化之后提供给业务系统，目标是将数据能力渗透到各个业务环 节，不限于决策分析类场景

## 业务价值 和 技术价值

业务价值：从洞察走向赋能业务创新，形成核心 壁垒

技术价值：能力多、成本低、应用广

# 技术体系

技术体系分两个层面：大数据存储计算技术和数据中台工具技术组件， 技术体系主要关注点是工具技术组件。大数据存储计算技术，比如 Hadoop、Spark、Flink、Greenplum、Elasticsearch、Redis、Phoenix等， 相对标准，企业只需要进行合理选型即可，并不需要自己建设，而且技 术难度很大，企业也不太可能自己建设。

# 数据中台架构

## 数据汇聚

数据汇聚是数据中台数据接入的入口。数据中台本身几乎不产生数据， 所有数据来自于业务系统、日志、文件、网络等，这些数据分散在不同 的网络环境和存储平台中，难以利用，很难产生业务价值。数据汇聚是数据中台必须提供的核心工具，把各种异构网络、异构数据源的数据方 便地采集到数据中台中进行集中存储，为后续的加工建模做准备。数据 汇聚方式一般有数据库同步、埋点、网络爬虫、消息队列等；从汇聚的 时效性来分，有离线批量汇聚和实时采集。

## 数据开发

数据开发是一整套数 据加工以及加工过程管控的工具，有经验的数据开发、算法建模人员利 用数据加工模块提供的功能，可以快速把数据加工成对业务有价值的形 式，提供给业务使用。

## 数据体系

有了数据汇聚、数据开发模块，中台已经具备传统数据仓库（后面简 称：数仓）平台的基本能力，可以做数据的汇聚以及各种数据开发，就 可以建立企业的数据体系。

笔者建议数据按照贴源数据、统一数仓、标签数据、 应用数据的标准统一建设。 

## 数据资产管理

数据资产管理包括对数据资产目 录、元数据、数据质量、数据血缘、数据生命周期等进行管理和展示， 以一种更直观的方式展现企业的数据资产，提升企业的数据意识。 

## 数据服务体系

数据服务体系就是把数 据变为一种服务能力，通过数据服务让数据参与到业务，激活整个数据 中台，数据服务体系是数据中台存在的价值所在。

数据中台的服务 模块并没有自带很多服务，而是提供快速的服务生成能力以及服务的管 控、鉴权、计量等功能。 

## 运营体系和安全管理

通过前面的数据汇聚、数据开发、数据体系、数据资产管理、数据服务 体系，已经完成了整个数据中台的搭建和建设，也已经在业务中发挥一 定的价值。

# 数据汇集联通

## 线上行为采集

### 客户端埋点 

常见的客户端埋点方式有三种：全埋点、可视化埋点和代码埋点。这三种方式的应用场景企业可根据自身需求进行选择。 

- 全埋点：将终端设备上用户的所有操作和内容都记录并保存下来，只 需要对内嵌SDK做一些初始配置就可以实现收集全部行为的目的。这也 经常被称为无痕埋点、无埋点等。 
- 可视化埋点：将终端设备上用户的一部分操作，通过服务端配置的方 式有选择性地记录并保存。 
- 代码埋点：根据需求来定制每次的收集内容，需要对相应的终端模块 进行升级。

### 服务端埋点

除了前面介绍的客户端埋点，常见的线上埋点还有服务端埋点，通过在 系统服务器端部署相应的数据采集模块，将这部分数据作为行为数据进 行处理和分析。

## 线下行为采集

线下行为数据主要通过一些硬件来采集，如常见的Wi-Fi探针、摄像 头、传感器等。随着设备的升级，各种场景中对智能设备的应用也越来 越多，安防、客户监测、考勤等都开始深入到生活中。常见的主要有 Wi-Fi信号采集、信令数据采集、图像视频采集以及传感器探测等。 

## 互联网数据采集

网络爬虫又称为网页蜘蛛，是一种按照既定规则自动抓取互联网信息的 程序或者脚本，常用来做网站的自动化测试和行为模拟。

网络爬虫有多种实现方式，目前有较多的开源框架 可以使用，如Apache Nutch 2、WebMagic、Scrapy、PHPCrawl等，可以 快速根据自己的实际应用场景去构建数据抓取逻辑。当然，需要遵守相 应的协议和法规，同时避免对目标网站造成过大的请求压力。 

## 内部数据汇聚

在数据建设过程中有ETL（Extract-Transform-Load，抽取–转换–存储） 的操作，即在数据抽取过程中进行数据的加工转换，然后加载至存储 中。

但在大规模数据场景下，一般不建议采用ETL的方式，建议采用 ELT（Extract-Load-Transform，抽取–存储–转换）的模式，即将数据抽 取后直接加载到存储中，再通过大数据和人工智能相关技术对数据进行 清洗和处理。

如果采用ETL的模式在传输过程中进行复杂的清洗，会因 为数据体量过大和清洗逻辑的复杂性导致数据传输的效率大大降低。

另 一方面，ETL模式在清洗过程中只提取有价值的信息进行存储，而是否 有价值是基于当前对数据的认知来判断的，由于数据价值会随着我们对数据的认知以及数据智能相关技术的发展而不断被挖掘，因此ETL模式 很容易出现一些有价值的数据被清洗掉，导致当某一天需要用这些数据 时，又需要重新处理，甚至数据丢失无法找回。相比存储的成本，这种 损失可能会更大。

### 开源工具

在数据能力建设过程中，很多企业结合自身的场景和最佳实践也开源了 一些优秀的汇聚工具，如Sqoop、DataX、Canal等，适用场景不同，也 各有优缺点。 

## 数据交换

### 数据源管理

- 关系型数据库：如Oracle、MySQL、SQL Server、Greenplum等。 
- NoSQL存储：如HBase、Redis、Elasticsearch、Cassandra、MongoDB、 Neo4J等。 
- 网络及MQ：如Kafka、HTTP等。 
- 文件系统：如HDFS、FTP、OSS、CSV、TXT、Excel等。 
- 大数据相关：如Hive、Impala、Kudu、MaxCompute、ADB、LibrA、 ELK等。 

## 数据开发

数据开发涉及的产品能力主要包括三个部分，分别是离线开发、实时开发和算法开发。

### 数据计算的4种能力

笔者们将计算能力根据场景抽象分成四大类：批计算、流计算、在线查 询和即席分析。

#### 批计算 

主要用于批量数据的高延时处理场景，如离线数仓的加工、大规模数据 的清洗和挖掘等。目前大多是利用MapReduce、Hive、Spark等计算框架 进行处理，其特点是数据吞吐量大、延时高，适合人机交互少的场景。 

#### 流计算 

也叫实时流计算，对于数据的加工处理和应用有较强的实效性要求，常 见于监控告警场景，例如实时分析网络事件，当有异常事件发生时能够 及时介入处理。例如，阿里巴巴“双11”的可视化大屏上的数据展现是根 据浏览、交易数据经过实时计算后展现在可视化大屏上的一种应用。这 类场景目前应用较多的计算框架主要有Flink、Spark Streaming和Storm 等。

#### 在线查询 

主要用于数据结果的在线查询、条件过滤和筛选等，如数据检索、条件 过滤等。根据不同的场景也会有多种选择，如营销场景对响应延时要求 高的，一般会采集缓存型的存储计算，如Redis、Tair等；对响应延时要 求正常的，可以选择HBase和MySQL等；需要进行条件过滤、检索的， 可以选择Elasticsearch等。企业一般对在线查询的需求比较旺盛，因此 可能会有多套在线计算的能力提供服务。 

#### 即席分析 

主要用于分析型场景和经验统计。一般而言，企业80%的数据处理需求 是在线查询和即席分析。针对不同维度的分析，有多种方式可以提供， 提前固定计算的维度、根据需求任意维度的交叉分析（ad-hoc）等都是 常见的场景。目前也有很多相应的产品、框架来支撑这方面的应用，如 Kylin、Impala、ClickHouse、Hawk等。 

### 离线开发

离线开发套件封装了大数据相关的技术，包括数据加工、数据分析、在 线查询、即席分析等能力，同时也将任务的调度、发布、运维、监控、 告警等进行整合，让开发者可以直接通过浏览器访问，不再需要安装任 何服务，也不用关心底层技术的实现，只需专注于业务的开发，帮助企 业快速构建数据服务，赋能业务。

### 实时开发

随着数据的应用场景越来越丰富，企业对于数据价值反馈到业务中的时 效性要求也越来越高，很早就有人提出过一个概念：数据的价值在于数 据的在线化。实时开发套件是对流计算能力的产品封装。实时计算起源 于对数据加工时效性的严苛需求：数据的业务价值随着时间的流逝会迅 速降低，因此在数据产生后必须尽快对其进行计算和处理。

### 算法开发

DT时代的数据具有高维稀疏特征，对算法处理提出了更高的要求。面 对百亿样本级别的数据量，传统的数据挖掘在辨识价值信息、挖掘数据 关系和数据趋势方面捉襟见肘。